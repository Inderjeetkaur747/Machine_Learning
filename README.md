This repository contains my complete Machine Learning learning path, implemented step-by-step in a single Jupyter Notebook.
It covers everything from data preprocessing â†’ supervised learning â†’ unsupervised learning â†’ ensemble learning, along with practical examples and visualizations.

I created this notebook to revise all ML concepts, strengthen my interview prep, and help others starting their ML journey.

 Whatâ€™s Inside the Notebook?
ğŸ”¹ 1. Data Cleaning & Preprocessing

Handling missing values

Outlier detection (IQR, Z-Score)

Data transformation & normalization

Label Encoding & One-Hot Encoding

Feature scaling (MinMax, StandardScaler)

Train/Test splitting

Handling imbalanced datasets (SMOTE)

ğŸ”¹ 2. Supervised Learning
Classification & Regression Models

Linear Regression

Logistic Regression

K-Nearest Neighbors (KNN)

Decision Tree

Random Forest

Support Vector Machine (SVM)

Naive Bayes

Model Evaluation Metrics:
Accuracy â€¢ Precision â€¢ Recall â€¢ F1-Score â€¢ Confusion Matrix â€¢ ROC-AUC

ğŸ”¹ 3. Unsupervised Learning

K-Means Clustering

Hierarchical Clustering

DBSCAN

PCA (Dimensionality Reduction)

Evaluation:
Elbow Method â€¢ Silhouette Score

ğŸ”¹ 4. Ensemble Learning

Bagging (Random Forest)

Boosting (AdaBoost, GradientBoosting, XGBoost)


Technologies Used

Python

NumPy

Pandas

Scikit-Learn

Matplotlib

Seaborn

XGBoost

Project Goal

This notebook helps to:

Build a strong understanding of ML foundations

Prepare for machine learning interviews

Strengthen GitHub portfolio with clean ML work


Future Add-ons

Feature engineering notebook

Hyperparameter tuning

Model deployment (FastAPI / Streamlit)

Deep Learning series (CNN, RNN, Transformers)

ğŸ¤ Connect With Me

If you find this useful or want to collaborate:

ğŸ”— LinkedIn: https://www.linkedin.com/in/inderjeet-kaur-31a2391ba/
Donâ€™t forget to star the repo!
